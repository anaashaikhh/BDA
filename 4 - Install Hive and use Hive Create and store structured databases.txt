1. start Hadoop:

su hduser
sudo service ssh start
ssh localhost
start-all.sh
jps

2. uninstall existing version:

cd /usr/local
sudo rm -r hive
hdfs dfs -rm -r -f /tmp
hdfs dfs -rm -r /user/hive

3. Create a text file sample.txt:

cd /home/hduser
sudo nano sample.txt

101,Shubham,15000,Clerk
102,Raj,50000,Manager
103,Rahul,150000,Director

4. Now we download and setup hive:

cd /usr/local
sudo wget https://downloads.apache.org/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
sudo tar -xvzf apache-hive-3.1.2-bin.tar.gz
sudo mv apache-hive-3.1.2-bin hive
sudo chmod 777 hive
cd /home/hduser

5. In the sudo nano .bashrc file, add these lines:

sudo nano .bashrc
export HIVE_HOME=/usr/local/hive
export PATH=$PATH:$HIVE_HOME/bin

source .bashrc

cd /usr/local/hive/bin

6. Add the following line to sudo nano hive-config.sh

export HADOOP_HOME=/usr/local/hadoop

7. Hive is installed now, but you need to first create some directories in HDFS for Hive to store its data.

hdfs dfs -mkdir /tmp
hdfs dfs -chmod g+w /tmp
hdfs dfs -mkdir -p /user/hive/warehouse
hdfs dfs -chmod g+w /user/hive/warehouse
sudo chmod 777 /usr/local/hive

8. initialize derby database.

cd $HIVE_HOME
$HIVE_HOME/bin/schematool -initSchema -dbType derby

9. You may face error like ‘NoSuchMethodFound’.
To solve it:

sudo cp $HADOOP_HOME/share/hadoop/common/lib/guava-27.0-jre.jar /usr/local/hive/lib/
sudo rm /usr/local/hive/lib/guava-19.0.jar

cd $HIVE_HOME
$HIVE_HOME/bin/schematool -initSchema -dbType derby

8. Start hive shell

hive

CREATE TABLE IF NOT EXISTS employee ( eid int, name String,salary String, designation String)COMMENT 'Employee details' ROW FORMAT DELIMITED FIELDS TERMINATED BY ','LINES TERMINATED BY '\n' STORED AS TEXTFILE;

LOAD DATA LOCAL INPATH "/home/hduser/sample.txt" into table employee;

select * from employee;

9. Then stop hadoop and close.
stop-all.sh






